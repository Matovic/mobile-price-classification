{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile price classification with multilayer perceptron\n",
    "## Tensorflow\n",
    "Erik Matovič and Jakub Horvat\n",
    "\n",
    "[Dataset](https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification?select=train.csv)\n",
    "\n",
    "Predict a price range indicating how high the price is\n",
    "\n",
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "from utils import split_train_val\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "#import wandb\n",
    "from utils import check_null_values, print_sum_null, rescale, split_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "Num GPUs Available:  0\n",
      "tf.Tensor(1828.2532, shape=(), dtype=float32)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing\n",
    "\n",
    "Based on [exploratory data analysis](EDA.ipynb) test set does not have target variable price_range. We split our dataset into train-dev-test. We have train and test sets, but we split test set by half to dev-test sets. We will rougly have train-dev-test 67%-16.5%-16.5%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n0               842     0          2.2         0   1       0           7   \n1              1021     1          0.5         1   0       1          53   \n2               563     1          0.5         1   2       1          41   \n3               615     1          2.5         0   0       0          10   \n4              1821     1          1.2         0  13       1          44   \n...             ...   ...          ...       ...  ..     ...         ...   \n1995            794     1          0.5         1   0       1           2   \n1996           1965     1          2.6         1   0       0          39   \n1997           1911     0          0.9         1   1       1          36   \n1998           1512     0          0.9         0   4       1          46   \n1999            510     1          2.0         1   5       1          45   \n\n      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n0       0.6        188        2  ...         20       756  2549     9     7   \n1       0.7        136        3  ...        905      1988  2631    17     3   \n2       0.9        145        5  ...       1263      1716  2603    11     2   \n3       0.8        131        6  ...       1216      1786  2769    16     8   \n4       0.6        141        2  ...       1208      1212  1411     8     2   \n...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n1995    0.8        106        6  ...       1222      1890   668    13     4   \n1996    0.2        187        4  ...        915      1965  2032    11    10   \n1997    0.7        108        8  ...        868      1632  3057     9     1   \n1998    0.1        145        5  ...        336       670   869    18    10   \n1999    0.9        168        6  ...        483       754  3919    19     4   \n\n      talk_time  three_g  touch_screen  wifi  price_range  \n0            19        0             0     1            1  \n1             7        1             1     0            2  \n2             9        1             1     0            2  \n3            11        1             0     0            2  \n4            15        1             1     0            1  \n...         ...      ...           ...   ...          ...  \n1995         19        1             1     0            0  \n1996         16        1             1     1            2  \n1997          5        1             1     0            3  \n1998         19        1             1     1            0  \n1999          2        1             1     1            3  \n\n[2000 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>battery_power</th>\n      <th>blue</th>\n      <th>clock_speed</th>\n      <th>dual_sim</th>\n      <th>fc</th>\n      <th>four_g</th>\n      <th>int_memory</th>\n      <th>m_dep</th>\n      <th>mobile_wt</th>\n      <th>n_cores</th>\n      <th>...</th>\n      <th>px_height</th>\n      <th>px_width</th>\n      <th>ram</th>\n      <th>sc_h</th>\n      <th>sc_w</th>\n      <th>talk_time</th>\n      <th>three_g</th>\n      <th>touch_screen</th>\n      <th>wifi</th>\n      <th>price_range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842</td>\n      <td>0</td>\n      <td>2.2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0.6</td>\n      <td>188</td>\n      <td>2</td>\n      <td>...</td>\n      <td>20</td>\n      <td>756</td>\n      <td>2549</td>\n      <td>9</td>\n      <td>7</td>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1021</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>53</td>\n      <td>0.7</td>\n      <td>136</td>\n      <td>3</td>\n      <td>...</td>\n      <td>905</td>\n      <td>1988</td>\n      <td>2631</td>\n      <td>17</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>563</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41</td>\n      <td>0.9</td>\n      <td>145</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1263</td>\n      <td>1716</td>\n      <td>2603</td>\n      <td>11</td>\n      <td>2</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>615</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.8</td>\n      <td>131</td>\n      <td>6</td>\n      <td>...</td>\n      <td>1216</td>\n      <td>1786</td>\n      <td>2769</td>\n      <td>16</td>\n      <td>8</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1821</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>44</td>\n      <td>0.6</td>\n      <td>141</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1208</td>\n      <td>1212</td>\n      <td>1411</td>\n      <td>8</td>\n      <td>2</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>794</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.8</td>\n      <td>106</td>\n      <td>6</td>\n      <td>...</td>\n      <td>1222</td>\n      <td>1890</td>\n      <td>668</td>\n      <td>13</td>\n      <td>4</td>\n      <td>19</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>1965</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>39</td>\n      <td>0.2</td>\n      <td>187</td>\n      <td>4</td>\n      <td>...</td>\n      <td>915</td>\n      <td>1965</td>\n      <td>2032</td>\n      <td>11</td>\n      <td>10</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>1911</td>\n      <td>0</td>\n      <td>0.9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>36</td>\n      <td>0.7</td>\n      <td>108</td>\n      <td>8</td>\n      <td>...</td>\n      <td>868</td>\n      <td>1632</td>\n      <td>3057</td>\n      <td>9</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>1512</td>\n      <td>0</td>\n      <td>0.9</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>46</td>\n      <td>0.1</td>\n      <td>145</td>\n      <td>5</td>\n      <td>...</td>\n      <td>336</td>\n      <td>670</td>\n      <td>869</td>\n      <td>18</td>\n      <td>10</td>\n      <td>19</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>510</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>45</td>\n      <td>0.9</td>\n      <td>168</td>\n      <td>6</td>\n      <td>...</td>\n      <td>483</td>\n      <td>754</td>\n      <td>3919</td>\n      <td>19</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read datasets\n",
    "df_train = pd.read_csv('../data/train.csv', sep=',')\n",
    "df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "data": {
      "text/plain": "       id  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n0       1           1043     1          1.8         1  14       0           5   \n1       2            841     1          0.5         1   4       1          61   \n2       3           1807     1          2.8         0   1       0          27   \n3       4           1546     0          0.5         1  18       1          25   \n4       5           1434     0          1.4         0  11       1          49   \n..    ...            ...   ...          ...       ...  ..     ...         ...   \n995   996           1700     1          1.9         0   0       1          54   \n996   997            609     0          1.8         1   0       0          13   \n997   998           1185     0          1.4         0   1       1           8   \n998   999           1533     1          0.5         1   0       0          50   \n999  1000           1270     1          0.5         0   4       1          35   \n\n     m_dep  mobile_wt  ...  pc  px_height  px_width   ram  sc_h  sc_w  \\\n0      0.1        193  ...  16        226      1412  3476    12     7   \n1      0.8        191  ...  12        746       857  3895     6     0   \n2      0.9        186  ...   4       1270      1366  2396    17    10   \n3      0.5         96  ...  20        295      1752  3893    10     0   \n4      0.5        108  ...  18        749       810  1773    15     8   \n..     ...        ...  ...  ..        ...       ...   ...   ...   ...   \n995    0.5        170  ...  17        644       913  2121    14     8   \n996    0.9        186  ...   2       1152      1632  1933     8     1   \n997    0.5         80  ...  12        477       825  1223     5     0   \n998    0.4        171  ...  12         38       832  2509    15    11   \n999    0.1        140  ...  19        457       608  2828     9     2   \n\n     talk_time  three_g  touch_screen  wifi  \n0            2        0             1     0  \n1            7        1             0     0  \n2           10        0             1     1  \n3            7        1             1     0  \n4            7        1             0     1  \n..         ...      ...           ...   ...  \n995         15        1             1     0  \n996         19        0             1     1  \n997         14        1             0     0  \n998          6        0             1     0  \n999          3        1             0     1  \n\n[1000 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>battery_power</th>\n      <th>blue</th>\n      <th>clock_speed</th>\n      <th>dual_sim</th>\n      <th>fc</th>\n      <th>four_g</th>\n      <th>int_memory</th>\n      <th>m_dep</th>\n      <th>mobile_wt</th>\n      <th>...</th>\n      <th>pc</th>\n      <th>px_height</th>\n      <th>px_width</th>\n      <th>ram</th>\n      <th>sc_h</th>\n      <th>sc_w</th>\n      <th>talk_time</th>\n      <th>three_g</th>\n      <th>touch_screen</th>\n      <th>wifi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1043</td>\n      <td>1</td>\n      <td>1.8</td>\n      <td>1</td>\n      <td>14</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0.1</td>\n      <td>193</td>\n      <td>...</td>\n      <td>16</td>\n      <td>226</td>\n      <td>1412</td>\n      <td>3476</td>\n      <td>12</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>841</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>61</td>\n      <td>0.8</td>\n      <td>191</td>\n      <td>...</td>\n      <td>12</td>\n      <td>746</td>\n      <td>857</td>\n      <td>3895</td>\n      <td>6</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1807</td>\n      <td>1</td>\n      <td>2.8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>27</td>\n      <td>0.9</td>\n      <td>186</td>\n      <td>...</td>\n      <td>4</td>\n      <td>1270</td>\n      <td>1366</td>\n      <td>2396</td>\n      <td>17</td>\n      <td>10</td>\n      <td>10</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1546</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>18</td>\n      <td>1</td>\n      <td>25</td>\n      <td>0.5</td>\n      <td>96</td>\n      <td>...</td>\n      <td>20</td>\n      <td>295</td>\n      <td>1752</td>\n      <td>3893</td>\n      <td>10</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1434</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>0</td>\n      <td>11</td>\n      <td>1</td>\n      <td>49</td>\n      <td>0.5</td>\n      <td>108</td>\n      <td>...</td>\n      <td>18</td>\n      <td>749</td>\n      <td>810</td>\n      <td>1773</td>\n      <td>15</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>996</td>\n      <td>1700</td>\n      <td>1</td>\n      <td>1.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>54</td>\n      <td>0.5</td>\n      <td>170</td>\n      <td>...</td>\n      <td>17</td>\n      <td>644</td>\n      <td>913</td>\n      <td>2121</td>\n      <td>14</td>\n      <td>8</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>997</td>\n      <td>609</td>\n      <td>0</td>\n      <td>1.8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>0.9</td>\n      <td>186</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1152</td>\n      <td>1632</td>\n      <td>1933</td>\n      <td>8</td>\n      <td>1</td>\n      <td>19</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>998</td>\n      <td>1185</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8</td>\n      <td>0.5</td>\n      <td>80</td>\n      <td>...</td>\n      <td>12</td>\n      <td>477</td>\n      <td>825</td>\n      <td>1223</td>\n      <td>5</td>\n      <td>0</td>\n      <td>14</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>999</td>\n      <td>1533</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>0.4</td>\n      <td>171</td>\n      <td>...</td>\n      <td>12</td>\n      <td>38</td>\n      <td>832</td>\n      <td>2509</td>\n      <td>15</td>\n      <td>11</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>1000</td>\n      <td>1270</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>35</td>\n      <td>0.1</td>\n      <td>140</td>\n      <td>...</td>\n      <td>19</td>\n      <td>457</td>\n      <td>608</td>\n      <td>2828</td>\n      <td>9</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../data/test.csv', sep=',', index_col=0)\n",
    "df_test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[8.420e+02, 0.000e+00, 2.200e+00, ..., 0.000e+00, 1.000e+00,\n        1.000e+00],\n       [1.021e+03, 1.000e+00, 5.000e-01, ..., 1.000e+00, 0.000e+00,\n        2.000e+00],\n       [5.630e+02, 1.000e+00, 5.000e-01, ..., 1.000e+00, 0.000e+00,\n        2.000e+00],\n       ...,\n       [1.911e+03, 0.000e+00, 9.000e-01, ..., 1.000e+00, 0.000e+00,\n        3.000e+00],\n       [1.512e+03, 0.000e+00, 9.000e-01, ..., 1.000e+00, 1.000e+00,\n        0.000e+00],\n       [5.100e+02, 1.000e+00, 2.000e+00, ..., 1.000e+00, 1.000e+00,\n        3.000e+00]])"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[8.420e+02, 0.000e+00, 2.200e+00, ..., 0.000e+00, 0.000e+00,\n        1.000e+00],\n       [1.021e+03, 1.000e+00, 5.000e-01, ..., 1.000e+00, 1.000e+00,\n        0.000e+00],\n       [5.630e+02, 1.000e+00, 5.000e-01, ..., 1.000e+00, 1.000e+00,\n        0.000e+00],\n       ...,\n       [1.911e+03, 0.000e+00, 9.000e-01, ..., 1.000e+00, 1.000e+00,\n        0.000e+00],\n       [1.512e+03, 0.000e+00, 9.000e-01, ..., 1.000e+00, 1.000e+00,\n        1.000e+00],\n       [5.100e+02, 1.000e+00, 2.000e+00, ..., 1.000e+00, 1.000e+00,\n        1.000e+00]], dtype=float32)"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df_train.values[:, :-1]       #vsetko okrem price range\n",
    "x_train = x_train.astype('float32')     # input data as floats\n",
    "x_train\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 ... 3 0 3]\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train.values[:, -1]  # price range\n",
    "y_train = y_train.astype('int')\n",
    "print(y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "x_test = df_test.values[:, :-1]       #vsetko okrem price range\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_test = df_test.values[:, -1]  # price range\n",
    "y_test = y_test.astype('int')\n",
    "print(x_test.shape,y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "# train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "#\n",
    "# # Print the dataset\n",
    "# for data, label in train_ds:\n",
    "#     print(data, label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# tf_train, tf_val = split_train_val(train_ds)\n",
    "#\n",
    "# print(tf_train.dataset)\n",
    "# print(tf_val.dataset)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "#shape(tf_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(16,input_shape=(20,),name='l1'),\n",
    "    keras.layers.Dense(16, activation='relu',name='l2'),\n",
    "    keras.layers.Dense(16, activation='relu',name='l3'),\n",
    "    keras.layers.Dense(1,activation='sigmoid',name='l4')\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 2s 2ms/step - loss: -469.1720 - accuracy: 0.2500\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -4684.4570 - accuracy: 0.2500\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -27761.4922 - accuracy: 0.2500\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -119955.8125 - accuracy: 0.2500\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -368752.4062 - accuracy: 0.2500\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -911529.5000 - accuracy: 0.2500\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -1919400.1250 - accuracy: 0.2500\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -3601429.7500 - accuracy: 0.2500\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -6158282.0000 - accuracy: 0.2500\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -9804326.0000 - accuracy: 0.2500\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -14778905.0000 - accuracy: 0.2500\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -21417436.0000 - accuracy: 0.2500\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -29960756.0000 - accuracy: 0.2500\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -40649784.0000 - accuracy: 0.2500\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -53921348.0000 - accuracy: 0.2500\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -69968880.0000 - accuracy: 0.2500\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -89106696.0000 - accuracy: 0.2500\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -111596120.0000 - accuracy: 0.2500\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -138025680.0000 - accuracy: 0.2500\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -168240464.0000 - accuracy: 0.2500\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -202950448.0000 - accuracy: 0.2500\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -242450720.0000 - accuracy: 0.2500\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -287032544.0000 - accuracy: 0.2500\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -336607136.0000 - accuracy: 0.2500\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -391634688.0000 - accuracy: 0.2500\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -453068896.0000 - accuracy: 0.2500\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -520684864.0000 - accuracy: 0.2500\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -594956864.0000 - accuracy: 0.2500\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -675996416.0000 - accuracy: 0.2500\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -765171392.0000 - accuracy: 0.2500\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -860469056.0000 - accuracy: 0.2500\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -963342016.0000 - accuracy: 0.2500\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -1074934656.0000 - accuracy: 0.2500\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -1194903808.0000 - accuracy: 0.2500\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -1323165056.0000 - accuracy: 0.2500\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -1461700096.0000 - accuracy: 0.2500\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -1608571904.0000 - accuracy: 0.2500\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -1765707264.0000 - accuracy: 0.2500\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -1932253952.0000 - accuracy: 0.2500\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -2109643008.0000 - accuracy: 0.2500\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -2296659712.0000 - accuracy: 0.2500\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -2494104832.0000 - accuracy: 0.2500\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -2702237440.0000 - accuracy: 0.2500\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -2922610176.0000 - accuracy: 0.2500\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -3152463616.0000 - accuracy: 0.2500\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -3394989056.0000 - accuracy: 0.2500\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -3651089664.0000 - accuracy: 0.2500\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -3918510848.0000 - accuracy: 0.2500\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -4200679680.0000 - accuracy: 0.2500\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -4494168064.0000 - accuracy: 0.2500\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -4800105472.0000 - accuracy: 0.2500\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -5120279040.0000 - accuracy: 0.2500\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -5452911616.0000 - accuracy: 0.2500\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -5800058880.0000 - accuracy: 0.2500\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -6161395200.0000 - accuracy: 0.2500\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -6534527488.0000 - accuracy: 0.2500\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -6926422016.0000 - accuracy: 0.2500\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -7331120128.0000 - accuracy: 0.2500\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -7752240640.0000 - accuracy: 0.2500\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -8187578368.0000 - accuracy: 0.2500\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -8641507328.0000 - accuracy: 0.2500\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -9109103616.0000 - accuracy: 0.2500\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -9595996160.0000 - accuracy: 0.2500\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -10097616896.0000 - accuracy: 0.2500\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -10613395456.0000 - accuracy: 0.2500\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -11151497216.0000 - accuracy: 0.2500\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -11702833152.0000 - accuracy: 0.2500\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -12272560128.0000 - accuracy: 0.2500\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -12862757888.0000 - accuracy: 0.2500\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -13469739008.0000 - accuracy: 0.2500\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -14098485248.0000 - accuracy: 0.2500\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -14740807680.0000 - accuracy: 0.2500\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -15408386048.0000 - accuracy: 0.2500\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: -16096578560.0000 - accuracy: 0.2500\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -16801260544.0000 - accuracy: 0.2500\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -17525975040.0000 - accuracy: 0.2500\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -18268913664.0000 - accuracy: 0.2500\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -19033022464.0000 - accuracy: 0.2500\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -19818121216.0000 - accuracy: 0.2500\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -20625999872.0000 - accuracy: 0.2500\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -21449979904.0000 - accuracy: 0.2500\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -22300805120.0000 - accuracy: 0.2500\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -23170734080.0000 - accuracy: 0.2500\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -24060917760.0000 - accuracy: 0.2500\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -24977741824.0000 - accuracy: 0.2500\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -25917880320.0000 - accuracy: 0.2500\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -26881691648.0000 - accuracy: 0.2500\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -27872856064.0000 - accuracy: 0.2500\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -28878696448.0000 - accuracy: 0.2500\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -29922287616.0000 - accuracy: 0.2500\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -30983544832.0000 - accuracy: 0.2500\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -32064466944.0000 - accuracy: 0.2500\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -33184167936.0000 - accuracy: 0.2500\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -34322173952.0000 - accuracy: 0.2500\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -35491577856.0000 - accuracy: 0.2500\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -36682461184.0000 - accuracy: 0.2500\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -37900849152.0000 - accuracy: 0.2500\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -39140184064.0000 - accuracy: 0.2500\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -40408477696.0000 - accuracy: 0.2500\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: -41705717760.0000 - accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x22e1d196a60>"
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=100)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test acc: [29663240192.0, 0.5070000290870667]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('test loss, test acc:', results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "(x_t, y_t), (x_te, y_te) = tf.keras.datasets.mnist.load_data()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_t)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(60000,)"
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_t)\n",
    "type(y_t)\n",
    "y_t.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
